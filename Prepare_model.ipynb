{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Projekt zaliczeniowy\n",
    "#### Bootcamp Data Science\n",
    "\n",
    "#### Temat 4 - Klasyfikacja obrazów. Celem projektu jest zastosowanie algorytmów do klasyfikacji do problemu rozpoznawania rasy psów przedstawionych na zdjęciu.\n",
    "\n",
    "Prace rozpocząłem od podzielenia zdjęć psów na 3 grupy:\n",
    "* train \n",
    "* validate\n",
    "* test\n",
    "\n",
    "Grupa treningowa była najbadziej liczna i otrzymała około 85% dostepnych zdjęć, grupa validacyjna otrzymała około 10% zdjęć, a testowa około 5%\n",
    "\n",
    "Z racji ograniczonych zasobów sprzętwych spośród 120 ras psów wybrałem 10:\n",
    "* 'NORWICH_TERRIER'\n",
    "* 'GERMAN_SHEPHERD'\n",
    "* 'MALTESE_DOG'\n",
    "* 'COLLIE'\n",
    "* 'VIZSLA'\n",
    "* 'KOMONDOR'\n",
    "* 'WHIPPET'\n",
    "* 'ESKIMO_DOG'\n",
    "* 'TIBETAN_MASTIFF'\n",
    "* 'WEIMARANER'\n",
    "\n",
    "Prace prowadziłem na komputerze stacjonarnym z systemem Lunux (Dystrybucja Ubuntu Mate 18.04) wyposażonym w:\n",
    "* intel i7 2600K@4.0GHz\n",
    "* 16 GB RAM DDR 3 1333 MHz XMP\n",
    "* Dysk SSD\n",
    "* Kartę graficzną Geforce 1070 TI z 8GB GDDR\n",
    "\n",
    "Prace rozpocząłem od podzielenia obrazków na 3 zbiory: treningowy(1276 zdjęć), validacyjny(220 zdjęć) i testowy(203 zdjęć)\n",
    "\n",
    "Z racji ograniczonych zasobów sprzetowych oraz tego żę chcę by wyniki były porównywalne wykorzystam obrazki w rozmiarze 75x75 (najmniejszy rozmiar obrazków akceptowalny przez gotowe modele uczenia głębokiego dostępne w Keras) - część zdjęć jest w pionie a część w poziomie więc wybrałem obrazki kwadratowe\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "import math\n",
    "import os\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPool2D, Dense, Dropout, Flatten, AvgPool2D\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
    "from keras import backend as K\n",
    "from keras.preprocessing import image\n",
    "from keras.applications.resnet50 import preprocess_input\n",
    "from keras.utils import np_utils\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.preprocessing import image\n",
    "from keras.applications.resnet50 import preprocess_input, decode_predictions\n",
    "\n",
    "from keras.applications.resnet50 import ResNet50\n",
    "from keras.applications.vgg16 import VGG16\n",
    "from keras.applications.vgg19 import VGG19\n",
    "from keras.applications.inception_resnet_v2 import InceptionResNetV2\n",
    "from keras.applications.inception_v3 import InceptionV3\n",
    "from keras.applications.mobilenet import MobileNet\n",
    "from keras.applications.xception import Xception\n",
    "\n",
    "from keras.optimizers import Adam, SGD\n",
    "from keras.regularizers import l2\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import architectures as A\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1276 images belonging to 10 classes.\n",
      "Found 220 images belonging to 10 classes.\n",
      "Found 203 images belonging to 10 classes.\n"
     ]
    }
   ],
   "source": [
    "train_data_dir = '/home/ralph/ml/Sages/Zaliczenie/Wybrane/train/'\n",
    "validation_data_dir = '/home/ralph/ml/Sages/Zaliczenie/Wybrane/validate/'\n",
    "test_data_dir = '/home/ralph/ml/Sages/Zaliczenie/Wybrane/test/'\n",
    "\n",
    "multiplier = 40 # 40 razy więcej obrazków wybierzemy z data generatora\n",
    "batch_size = 32\n",
    "w=75\n",
    "h=75\n",
    "\n",
    "train_datagen = ImageDataGenerator(rescale=1./255,\n",
    "                                shear_range=0.2,\n",
    "                                zoom_range=0.2,\n",
    "                                rotation_range=30,\n",
    "                                horizontal_flip=True)\n",
    "validation_datagen = ImageDataGenerator(rescale=1./255)\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(train_data_dir,\n",
    "                                                    target_size=(h, w),\n",
    "                                                    batch_size=batch_size, \n",
    "                                                    class_mode='categorical',\n",
    "                                                       shuffle=True)\n",
    "validation_generator = validation_datagen.flow_from_directory(validation_data_dir,\n",
    "                                                        target_size=(h, w),\n",
    "                                                        batch_size=220, # liczba wszystkich obrazków w zbiorze\n",
    "                                                        class_mode='categorical',\n",
    "                                                       shuffle=False)\n",
    "test_generator = test_datagen.flow_from_directory(test_data_dir,\n",
    "                                                        target_size=(h, w),\n",
    "                                                        batch_size=203, # liczba wszystkich obrazków w zbiorze\n",
    "                                                        class_mode='categorical',\n",
    "                                                        shuffle=False)\n",
    "\n",
    "num_classes = train_generator.num_classes\n",
    "image_shape = train_generator.image_shape\n",
    "\n",
    "nb_train_samples = train_generator.n\n",
    "nb_validation_samples = validation_generator.n\n",
    "nb_test_samples = test_generator.n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = '/home/ralph/ml/Sages/Zaliczenie/final/class_indices'\n",
    "outfile = open(filename,'wb')\n",
    "pickle.dump(test_generator.class_indices,outfile)\n",
    "outfile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/ralph/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    }
   ],
   "source": [
    "# Ustawienie parametrów przekazywanych do modeli\n",
    "\n",
    "callbacks = [ \n",
    "    EarlyStopping(patience=3,monitor=\"val_loss\", restore_best_weights=True),\n",
    "    ReduceLROnPlateau(patience=2) # Gdy przez 2 epoki nie będzie poprawy zmniejszy LR o 10%\n",
    "]\n",
    "\n",
    "# 0.0001, decay=0.00000001\n",
    "optimizer = Adam()\n",
    "\n",
    "regularizer = l2(0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/ralph/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 75, 75, 8)         224       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 37, 37, 8)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 37, 37, 16)        1168      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 18, 18, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 18, 18, 32)        4640      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 9, 9, 32)          0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 2592)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 128)               331904    \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 339,226\n",
      "Trainable params: 339,226\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "WARNING:tensorflow:From /home/ralph/anaconda3/lib/python3.7/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Epoch 1/100\n",
      "1595/1595 [==============================] - 48s 30ms/step - loss: 1.0064 - acc: 0.7040 - val_loss: 2.5200 - val_acc: 0.3409\n",
      "Epoch 2/100\n",
      "1595/1595 [==============================] - 45s 28ms/step - loss: 0.6441 - acc: 0.8340 - val_loss: 3.0582 - val_acc: 0.3273\n",
      "Epoch 3/100\n",
      "1595/1595 [==============================] - 45s 29ms/step - loss: 0.4972 - acc: 0.8852 - val_loss: 3.2239 - val_acc: 0.4000\n",
      "Epoch 4/100\n",
      "1595/1595 [==============================] - 45s 28ms/step - loss: 0.8293 - acc: 0.7677 - val_loss: 2.7210 - val_acc: 0.3955\n"
     ]
    }
   ],
   "source": [
    "model, eval_arch_1 = A.arch_1(image_shape, num_classes, callbacks, train_generator, nb_train_samples*multiplier,\\\n",
    "                       validation_generator,nb_validation_samples,batch_size,test_generator,nb_test_samples,\\\n",
    "                      regularizer,optimizer)\n",
    "filename = '/home/ralph/ml/Sages/Zaliczenie/final/results/eval_arch_1'\n",
    "outfile = open(filename,'wb')\n",
    "pickle.dump(eval_arch_1,outfile)\n",
    "outfile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_4 (Conv2D)            (None, 75, 75, 32)        896       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 37, 37, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 37, 37, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2 (None, 18, 18, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 18, 18, 128)       73856     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_6 (MaxPooling2 (None, 9, 9, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 10368)             0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 128)               1327232   \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 1,421,770\n",
      "Trainable params: 1,421,770\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "1595/1595 [==============================] - 48s 30ms/step - loss: 1.4454 - acc: 0.5118 - val_loss: 2.1284 - val_acc: 0.4045\n",
      "Epoch 2/100\n",
      "1595/1595 [==============================] - 46s 29ms/step - loss: 1.1159 - acc: 0.6332 - val_loss: 2.1301 - val_acc: 0.3727\n",
      "Epoch 3/100\n",
      "1595/1595 [==============================] - 46s 29ms/step - loss: 0.8489 - acc: 0.7284 - val_loss: 2.3047 - val_acc: 0.4364\n",
      "Epoch 4/100\n",
      "1595/1595 [==============================] - 46s 29ms/step - loss: 1.0403 - acc: 0.6502 - val_loss: 1.9577 - val_acc: 0.4545\n",
      "Epoch 5/100\n",
      "1595/1595 [==============================] - 46s 29ms/step - loss: 0.9536 - acc: 0.6793 - val_loss: 1.9746 - val_acc: 0.4636\n",
      "Epoch 6/100\n",
      "1595/1595 [==============================] - 46s 29ms/step - loss: 0.9259 - acc: 0.6830 - val_loss: 2.0183 - val_acc: 0.4500\n",
      "Epoch 7/100\n",
      "1595/1595 [==============================] - 46s 29ms/step - loss: 0.9431 - acc: 0.6811 - val_loss: 1.9514 - val_acc: 0.4500\n",
      "Epoch 8/100\n",
      "1595/1595 [==============================] - 46s 29ms/step - loss: 0.9349 - acc: 0.6821 - val_loss: 1.9297 - val_acc: 0.4455\n",
      "Epoch 9/100\n",
      "1595/1595 [==============================] - 47s 30ms/step - loss: 0.9476 - acc: 0.6807 - val_loss: 1.9424 - val_acc: 0.4500\n",
      "Epoch 10/100\n",
      "1595/1595 [==============================] - 47s 29ms/step - loss: 0.9371 - acc: 0.6828 - val_loss: 1.9321 - val_acc: 0.4500\n",
      "Epoch 11/100\n",
      "1595/1595 [==============================] - 46s 29ms/step - loss: 0.9200 - acc: 0.6872 - val_loss: 1.9406 - val_acc: 0.4455\n"
     ]
    }
   ],
   "source": [
    "model, eval_arch_2 = A.arch_2(image_shape, num_classes, callbacks, train_generator, nb_train_samples*multiplier,\\\n",
    "                       validation_generator,nb_validation_samples,batch_size,test_generator,nb_test_samples,\\\n",
    "                      regularizer,optimizer)\n",
    "filename = '/home/ralph/ml/Sages/Zaliczenie/final/results/eval_arch_2'\n",
    "outfile = open(filename,'wb')\n",
    "pickle.dump(eval_arch_2,outfile)\n",
    "outfile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_7 (Conv2D)            (None, 75, 75, 32)        896       \n",
      "_________________________________________________________________\n",
      "conv2d_8 (Conv2D)            (None, 75, 75, 32)        9248      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_7 (MaxPooling2 (None, 37, 37, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_9 (Conv2D)            (None, 37, 37, 64)        18496     \n",
      "_________________________________________________________________\n",
      "conv2d_10 (Conv2D)           (None, 37, 37, 64)        36928     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_8 (MaxPooling2 (None, 18, 18, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_11 (Conv2D)           (None, 18, 18, 128)       73856     \n",
      "_________________________________________________________________\n",
      "conv2d_12 (Conv2D)           (None, 18, 18, 128)       147584    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_9 (MaxPooling2 (None, 9, 9, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten_3 (Flatten)          (None, 10368)             0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 128)               1327232   \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 1,615,530\n",
      "Trainable params: 1,615,530\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "1595/1595 [==============================] - 50s 32ms/step - loss: 2.3259 - acc: 0.1019 - val_loss: 2.3261 - val_acc: 0.1000\n",
      "Epoch 2/100\n",
      "1595/1595 [==============================] - 48s 30ms/step - loss: 2.3191 - acc: 0.1489 - val_loss: 2.3254 - val_acc: 0.1000\n",
      "Epoch 3/100\n",
      "1595/1595 [==============================] - 48s 30ms/step - loss: 2.3144 - acc: 0.1632 - val_loss: 2.3252 - val_acc: 0.1000\n",
      "Epoch 4/100\n",
      "1595/1595 [==============================] - 48s 30ms/step - loss: 2.3096 - acc: 0.1636 - val_loss: 2.3249 - val_acc: 0.1000\n",
      "Epoch 5/100\n",
      "1595/1595 [==============================] - 48s 30ms/step - loss: 2.3053 - acc: 0.1645 - val_loss: 2.3247 - val_acc: 0.1000\n",
      "Epoch 6/100\n",
      "1595/1595 [==============================] - 48s 30ms/step - loss: 2.3007 - acc: 0.1636 - val_loss: 2.3248 - val_acc: 0.1000\n",
      "Epoch 7/100\n",
      "1595/1595 [==============================] - 48s 30ms/step - loss: 2.2959 - acc: 0.1660 - val_loss: 2.3247 - val_acc: 0.1000\n",
      "Epoch 8/100\n",
      "1595/1595 [==============================] - 48s 30ms/step - loss: 2.2963 - acc: 0.1613 - val_loss: 2.3246 - val_acc: 0.1000\n",
      "Epoch 9/100\n",
      "1595/1595 [==============================] - 48s 30ms/step - loss: 2.2956 - acc: 0.1652 - val_loss: 2.3246 - val_acc: 0.1000\n",
      "Epoch 10/100\n",
      "1595/1595 [==============================] - 48s 30ms/step - loss: 2.2937 - acc: 0.1634 - val_loss: 2.3246 - val_acc: 0.1000\n",
      "Epoch 11/100\n",
      "1595/1595 [==============================] - 48s 30ms/step - loss: 2.2937 - acc: 0.1642 - val_loss: 2.3246 - val_acc: 0.1000\n",
      "Epoch 12/100\n",
      "1595/1595 [==============================] - 48s 30ms/step - loss: 2.2952 - acc: 0.1629 - val_loss: 2.3246 - val_acc: 0.1000\n",
      "Epoch 13/100\n",
      "1595/1595 [==============================] - 48s 30ms/step - loss: 2.2934 - acc: 0.1656 - val_loss: 2.3246 - val_acc: 0.1000\n",
      "Epoch 14/100\n",
      "1595/1595 [==============================] - 48s 30ms/step - loss: 2.2951 - acc: 0.1636 - val_loss: 2.3246 - val_acc: 0.1000\n",
      "Epoch 15/100\n",
      "1595/1595 [==============================] - 48s 30ms/step - loss: 2.2950 - acc: 0.1650 - val_loss: 2.3246 - val_acc: 0.1000\n"
     ]
    }
   ],
   "source": [
    "model, eval_arch_3 = A.arch_3(image_shape, num_classes, callbacks, train_generator, nb_train_samples*multiplier,\\\n",
    "                       validation_generator,nb_validation_samples,batch_size,test_generator,nb_test_samples,\\\n",
    "                      regularizer,optimizer)\n",
    "filename = '/home/ralph/ml/Sages/Zaliczenie/final/results/eval_arch_3'\n",
    "outfile = open(filename,'wb')\n",
    "pickle.dump(eval_arch_3,outfile)\n",
    "outfile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_13 (Conv2D)           (None, 75, 75, 32)        896       \n",
      "_________________________________________________________________\n",
      "conv2d_14 (Conv2D)           (None, 75, 75, 32)        9248      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_10 (MaxPooling (None, 37, 37, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_15 (Conv2D)           (None, 37, 37, 64)        18496     \n",
      "_________________________________________________________________\n",
      "conv2d_16 (Conv2D)           (None, 37, 37, 64)        36928     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_11 (MaxPooling (None, 18, 18, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_17 (Conv2D)           (None, 18, 18, 128)       73856     \n",
      "_________________________________________________________________\n",
      "conv2d_18 (Conv2D)           (None, 18, 18, 128)       147584    \n",
      "_________________________________________________________________\n",
      "conv2d_19 (Conv2D)           (None, 18, 18, 128)       147584    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_12 (MaxPooling (None, 9, 9, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_20 (Conv2D)           (None, 9, 9, 128)         147584    \n",
      "_________________________________________________________________\n",
      "conv2d_21 (Conv2D)           (None, 9, 9, 128)         147584    \n",
      "_________________________________________________________________\n",
      "conv2d_22 (Conv2D)           (None, 9, 9, 128)         147584    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_13 (MaxPooling (None, 4, 4, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten_4 (Flatten)          (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 128)               262272    \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 1,140,906\n",
      "Trainable params: 1,140,906\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "1595/1595 [==============================] - 50s 31ms/step - loss: 2.3273 - acc: 0.0875 - val_loss: 2.3263 - val_acc: 0.1182\n",
      "Epoch 2/100\n",
      "1595/1595 [==============================] - 47s 30ms/step - loss: 2.3273 - acc: 0.0861 - val_loss: 2.3263 - val_acc: 0.1182\n",
      "Epoch 3/100\n",
      "1595/1595 [==============================] - 48s 30ms/step - loss: 2.3273 - acc: 0.0881 - val_loss: 2.3263 - val_acc: 0.1182\n",
      "Epoch 4/100\n",
      "1595/1595 [==============================] - 47s 30ms/step - loss: 2.3274 - acc: 0.0856 - val_loss: 2.3263 - val_acc: 0.1182\n"
     ]
    }
   ],
   "source": [
    "model, eval_arch_4 = A.arch_4(image_shape, num_classes, callbacks, train_generator, nb_train_samples*multiplier,\\\n",
    "                       validation_generator,nb_validation_samples,batch_size,test_generator,nb_test_samples,\\\n",
    "                      regularizer,optimizer)\n",
    "filename = '/home/ralph/ml/Sages/Zaliczenie/final/results/eval_arch_4'\n",
    "outfile = open(filename,'wb')\n",
    "pickle.dump(eval_arch_4,outfile)\n",
    "outfile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_23 (Conv2D)           (None, 75, 75, 32)        896       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_14 (MaxPooling (None, 37, 37, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_24 (Conv2D)           (None, 37, 37, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_15 (MaxPooling (None, 18, 18, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_25 (Conv2D)           (None, 18, 18, 128)       73856     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_16 (MaxPooling (None, 9, 9, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten_5 (Flatten)          (None, 10368)             0         \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 512)               5308928   \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 128)               65664     \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 5,469,130\n",
      "Trainable params: 5,469,130\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "1595/1595 [==============================] - 49s 31ms/step - loss: 2.4244 - acc: 0.0979 - val_loss: 2.4245 - val_acc: 0.0682\n",
      "Epoch 2/100\n",
      "1595/1595 [==============================] - 46s 29ms/step - loss: 2.4230 - acc: 0.0996 - val_loss: 2.4245 - val_acc: 0.0682\n",
      "Epoch 3/100\n",
      "1595/1595 [==============================] - 47s 29ms/step - loss: 2.4234 - acc: 0.0994 - val_loss: 2.4245 - val_acc: 0.0682\n",
      "Epoch 4/100\n",
      "1595/1595 [==============================] - 46s 29ms/step - loss: 2.4240 - acc: 0.0968 - val_loss: 2.4245 - val_acc: 0.0682\n"
     ]
    }
   ],
   "source": [
    "model, eval_arch_5 = A.arch_5(image_shape, num_classes, callbacks, train_generator, nb_train_samples*multiplier,\\\n",
    "                       validation_generator,nb_validation_samples,batch_size,test_generator,nb_test_samples,\\\n",
    "                      regularizer,optimizer)\n",
    "filename = '/home/ralph/ml/Sages/Zaliczenie/final/results/eval_arch_5'\n",
    "outfile = open(filename,'wb')\n",
    "pickle.dump(eval_arch_5,outfile)\n",
    "outfile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_26 (Conv2D)           (None, 75, 75, 32)        896       \n",
      "_________________________________________________________________\n",
      "conv2d_27 (Conv2D)           (None, 75, 75, 32)        9248      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_17 (MaxPooling (None, 37, 37, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_28 (Conv2D)           (None, 37, 37, 64)        18496     \n",
      "_________________________________________________________________\n",
      "conv2d_29 (Conv2D)           (None, 37, 37, 64)        36928     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_18 (MaxPooling (None, 18, 18, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_30 (Conv2D)           (None, 18, 18, 128)       73856     \n",
      "_________________________________________________________________\n",
      "conv2d_31 (Conv2D)           (None, 18, 18, 128)       147584    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_19 (MaxPooling (None, 9, 9, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten_6 (Flatten)          (None, 10368)             0         \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 512)               5308928   \n",
      "_________________________________________________________________\n",
      "dropout_7 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 128)               65664     \n",
      "_________________________________________________________________\n",
      "dropout_8 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 5,662,890\n",
      "Trainable params: 5,662,890\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "1595/1595 [==============================] - 51s 32ms/step - loss: 2.4239 - acc: 0.0929 - val_loss: 2.4195 - val_acc: 0.1000\n",
      "Epoch 2/100\n",
      "1595/1595 [==============================] - 47s 30ms/step - loss: 2.4247 - acc: 0.0895 - val_loss: 2.4195 - val_acc: 0.1000\n",
      "Epoch 3/100\n",
      "1595/1595 [==============================] - 48s 30ms/step - loss: 2.4238 - acc: 0.0930 - val_loss: 2.4195 - val_acc: 0.1000\n",
      "Epoch 4/100\n",
      "1595/1595 [==============================] - 48s 30ms/step - loss: 2.4239 - acc: 0.0943 - val_loss: 2.4195 - val_acc: 0.1000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model, eval_arch_6 = A.arch_6(image_shape, num_classes, callbacks, train_generator, nb_train_samples*multiplier,\\\n",
    "                       validation_generator,nb_validation_samples,batch_size,test_generator,nb_test_samples,\\\n",
    "                      regularizer,optimizer)\n",
    "filename = '/home/ralph/ml/Sages/Zaliczenie/final/results/eval_arch_6'\n",
    "outfile = open(filename,'wb')\n",
    "pickle.dump(eval_arch_6,outfile)\n",
    "outfile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_32 (Conv2D)           (None, 75, 75, 32)        896       \n",
      "_________________________________________________________________\n",
      "conv2d_33 (Conv2D)           (None, 75, 75, 32)        9248      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_20 (MaxPooling (None, 37, 37, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_34 (Conv2D)           (None, 37, 37, 64)        18496     \n",
      "_________________________________________________________________\n",
      "conv2d_35 (Conv2D)           (None, 37, 37, 64)        36928     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_21 (MaxPooling (None, 18, 18, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_36 (Conv2D)           (None, 18, 18, 128)       73856     \n",
      "_________________________________________________________________\n",
      "conv2d_37 (Conv2D)           (None, 18, 18, 128)       147584    \n",
      "_________________________________________________________________\n",
      "conv2d_38 (Conv2D)           (None, 18, 18, 128)       147584    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_22 (MaxPooling (None, 9, 9, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_39 (Conv2D)           (None, 9, 9, 128)         147584    \n",
      "_________________________________________________________________\n",
      "conv2d_40 (Conv2D)           (None, 9, 9, 128)         147584    \n",
      "_________________________________________________________________\n",
      "conv2d_41 (Conv2D)           (None, 9, 9, 128)         147584    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_23 (MaxPooling (None, 4, 4, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten_7 (Flatten)          (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "dense_15 (Dense)             (None, 512)               1049088   \n",
      "_________________________________________________________________\n",
      "dropout_9 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_16 (Dense)             (None, 128)               65664     \n",
      "_________________________________________________________________\n",
      "dropout_10 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_17 (Dense)             (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 1,993,386\n",
      "Trainable params: 1,993,386\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "1595/1595 [==============================] - 53s 33ms/step - loss: 2.4050 - acc: 0.1033 - val_loss: 2.4048 - val_acc: 0.1091\n",
      "Epoch 2/100\n",
      "1595/1595 [==============================] - 49s 31ms/step - loss: 2.4051 - acc: 0.1008 - val_loss: 2.4048 - val_acc: 0.1091\n",
      "Epoch 3/100\n",
      "1595/1595 [==============================] - 50s 31ms/step - loss: 2.4051 - acc: 0.1004 - val_loss: 2.4048 - val_acc: 0.1091\n",
      "Epoch 4/100\n",
      "1595/1595 [==============================] - 49s 31ms/step - loss: 2.4052 - acc: 0.0989 - val_loss: 2.4048 - val_acc: 0.1091\n"
     ]
    }
   ],
   "source": [
    "model, eval_arch_7 = A.arch_7(image_shape, num_classes, callbacks, train_generator, nb_train_samples*multiplier,\\\n",
    "                       validation_generator,nb_validation_samples,batch_size,test_generator,nb_test_samples,\\\n",
    "                      regularizer,optimizer)\n",
    "filename = '/home/ralph/ml/Sages/Zaliczenie/final/results/eval_arch_7'\n",
    "outfile = open(filename,'wb')\n",
    "pickle.dump(eval_arch_7,outfile)\n",
    "outfile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_42 (Conv2D)           (None, 75, 75, 32)        896       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_24 (MaxPooling (None, 37, 37, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_43 (Conv2D)           (None, 37, 37, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_25 (MaxPooling (None, 18, 18, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_44 (Conv2D)           (None, 18, 18, 128)       73856     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_26 (MaxPooling (None, 9, 9, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten_8 (Flatten)          (None, 10368)             0         \n",
      "_________________________________________________________________\n",
      "dense_18 (Dense)             (None, 1024)              10617856  \n",
      "_________________________________________________________________\n",
      "dropout_11 (Dropout)         (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_19 (Dense)             (None, 512)               524800    \n",
      "_________________________________________________________________\n",
      "dropout_12 (Dropout)         (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_20 (Dense)             (None, 128)               65664     \n",
      "_________________________________________________________________\n",
      "dropout_13 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_21 (Dense)             (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 11,302,858\n",
      "Trainable params: 11,302,858\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "1595/1595 [==============================] - 52s 33ms/step - loss: 2.5831 - acc: 0.0925 - val_loss: 2.5818 - val_acc: 0.1045\n",
      "Epoch 2/100\n",
      "1595/1595 [==============================] - 48s 30ms/step - loss: 2.5843 - acc: 0.0916 - val_loss: 2.5818 - val_acc: 0.1045\n",
      "Epoch 3/100\n",
      "1595/1595 [==============================] - 48s 30ms/step - loss: 2.5831 - acc: 0.0958 - val_loss: 2.5818 - val_acc: 0.1045\n",
      "Epoch 4/100\n",
      "1595/1595 [==============================] - 49s 31ms/step - loss: 2.5839 - acc: 0.0903 - val_loss: 2.5818 - val_acc: 0.1045\n"
     ]
    }
   ],
   "source": [
    "model, eval_arch_8 = A.arch_8(image_shape, num_classes, callbacks, train_generator, nb_train_samples*multiplier,\\\n",
    "                       validation_generator,nb_validation_samples,batch_size,test_generator,nb_test_samples,\\\n",
    "                      regularizer,optimizer)\n",
    "filename = '/home/ralph/ml/Sages/Zaliczenie/final/results/eval_arch_8'\n",
    "outfile = open(filename,'wb')\n",
    "pickle.dump(eval_arch_8,outfile)\n",
    "outfile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_45 (Conv2D)           (None, 75, 75, 32)        896       \n",
      "_________________________________________________________________\n",
      "conv2d_46 (Conv2D)           (None, 75, 75, 32)        9248      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_27 (MaxPooling (None, 37, 37, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_47 (Conv2D)           (None, 37, 37, 64)        18496     \n",
      "_________________________________________________________________\n",
      "conv2d_48 (Conv2D)           (None, 37, 37, 64)        36928     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_28 (MaxPooling (None, 18, 18, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_49 (Conv2D)           (None, 18, 18, 128)       73856     \n",
      "_________________________________________________________________\n",
      "conv2d_50 (Conv2D)           (None, 18, 18, 128)       147584    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_29 (MaxPooling (None, 9, 9, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten_9 (Flatten)          (None, 10368)             0         \n",
      "_________________________________________________________________\n",
      "dense_22 (Dense)             (None, 1024)              10617856  \n",
      "_________________________________________________________________\n",
      "dropout_14 (Dropout)         (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_23 (Dense)             (None, 512)               524800    \n",
      "_________________________________________________________________\n",
      "dropout_15 (Dropout)         (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_24 (Dense)             (None, 128)               65664     \n",
      "_________________________________________________________________\n",
      "dropout_16 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_25 (Dense)             (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 11,496,618\n",
      "Trainable params: 11,496,618\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "1595/1595 [==============================] - 58s 36ms/step - loss: 2.5765 - acc: 0.1094 - val_loss: 2.5791 - val_acc: 0.1045\n",
      "Epoch 2/100\n",
      "1595/1595 [==============================] - 54s 34ms/step - loss: 2.5761 - acc: 0.1091 - val_loss: 2.5791 - val_acc: 0.1045\n",
      "Epoch 3/100\n",
      "1595/1595 [==============================] - 54s 34ms/step - loss: 2.5759 - acc: 0.1077 - val_loss: 2.5791 - val_acc: 0.1045\n",
      "Epoch 4/100\n",
      "1595/1595 [==============================] - 54s 34ms/step - loss: 2.5763 - acc: 0.1062 - val_loss: 2.5791 - val_acc: 0.1045\n"
     ]
    }
   ],
   "source": [
    "model, eval_arch_9 = A.arch_9(image_shape, num_classes, callbacks, train_generator, nb_train_samples*multiplier,\\\n",
    "                       validation_generator,nb_validation_samples,batch_size,test_generator,nb_test_samples,\\\n",
    "                      regularizer,optimizer)\n",
    "filename = '/home/ralph/ml/Sages/Zaliczenie/final/results/eval_arch_9'\n",
    "outfile = open(filename,'wb')\n",
    "pickle.dump(eval_arch_9,outfile)\n",
    "outfile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_51 (Conv2D)           (None, 75, 75, 32)        896       \n",
      "_________________________________________________________________\n",
      "conv2d_52 (Conv2D)           (None, 75, 75, 32)        9248      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_30 (MaxPooling (None, 37, 37, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_53 (Conv2D)           (None, 37, 37, 64)        18496     \n",
      "_________________________________________________________________\n",
      "conv2d_54 (Conv2D)           (None, 37, 37, 64)        36928     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_31 (MaxPooling (None, 18, 18, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_55 (Conv2D)           (None, 18, 18, 128)       73856     \n",
      "_________________________________________________________________\n",
      "conv2d_56 (Conv2D)           (None, 18, 18, 128)       147584    \n",
      "_________________________________________________________________\n",
      "conv2d_57 (Conv2D)           (None, 18, 18, 128)       147584    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_32 (MaxPooling (None, 9, 9, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_58 (Conv2D)           (None, 9, 9, 128)         147584    \n",
      "_________________________________________________________________\n",
      "conv2d_59 (Conv2D)           (None, 9, 9, 128)         147584    \n",
      "_________________________________________________________________\n",
      "conv2d_60 (Conv2D)           (None, 9, 9, 128)         147584    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_33 (MaxPooling (None, 4, 4, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten_10 (Flatten)         (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "dense_26 (Dense)             (None, 1024)              2098176   \n",
      "_________________________________________________________________\n",
      "dropout_17 (Dropout)         (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_27 (Dense)             (None, 512)               524800    \n",
      "_________________________________________________________________\n",
      "dropout_18 (Dropout)         (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_28 (Dense)             (None, 128)               65664     \n",
      "_________________________________________________________________\n",
      "dropout_19 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_29 (Dense)             (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 3,567,274\n",
      "Trainable params: 3,567,274\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "1595/1595 [==============================] - 54s 34ms/step - loss: 2.5281 - acc: 0.0938 - val_loss: 2.5280 - val_acc: 0.1000\n",
      "Epoch 2/100\n",
      "1595/1595 [==============================] - 51s 32ms/step - loss: 2.5281 - acc: 0.0915 - val_loss: 2.5280 - val_acc: 0.1000\n",
      "Epoch 3/100\n",
      "1595/1595 [==============================] - 51s 32ms/step - loss: 2.5281 - acc: 0.0919 - val_loss: 2.5280 - val_acc: 0.1000\n",
      "Epoch 4/100\n",
      "1595/1595 [==============================] - 51s 32ms/step - loss: 2.5281 - acc: 0.0928 - val_loss: 2.5280 - val_acc: 0.1000\n"
     ]
    }
   ],
   "source": [
    "model, eval_arch_10 = A.arch_10(image_shape, num_classes, callbacks, train_generator, nb_train_samples*multiplier,\\\n",
    "                       validation_generator,nb_validation_samples,batch_size,test_generator,nb_test_samples,\\\n",
    "                      regularizer,optimizer)\n",
    "filename = '/home/ralph/ml/Sages/Zaliczenie/final/results/eval_arch_10'\n",
    "outfile = open(filename,'wb')\n",
    "pickle.dump(eval_arch_10,outfile)\n",
    "outfile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Architektura: eval_arch_9 miałą acc na zbiorze testowym równe: 0.10\n",
      "Architektura: eval_arch_6 miałą acc na zbiorze testowym równe: 0.08\n",
      "Architektura: eval_arch_8 miałą acc na zbiorze testowym równe: 0.09\n",
      "Architektura: eval_arch_7 miałą acc na zbiorze testowym równe: 0.09\n",
      "Architektura: eval_arch_10 miałą acc na zbiorze testowym równe: 0.11\n",
      "Architektura: eval_arch_2 miałą acc na zbiorze testowym równe: 0.39\n",
      "Architektura: eval_arch_4 miałą acc na zbiorze testowym równe: 0.10\n",
      "Architektura: eval_arch_3 miałą acc na zbiorze testowym równe: 0.10\n",
      "Architektura: eval_arch_1 miałą acc na zbiorze testowym równe: 0.30\n",
      "Architektura: eval_arch_5 miałą acc na zbiorze testowym równe: 0.11\n"
     ]
    }
   ],
   "source": [
    "scores=[]\n",
    "\n",
    "for folder in os.walk('/home/ralph/ml/Sages/Zaliczenie/final/results'):\n",
    "    for file in folder[2]:\n",
    "        filename = '/home/ralph/ml/Sages/Zaliczenie/final/results/' + file\n",
    "        infile = open(filename,'rb')\n",
    "        a=pickle.load(infile)\n",
    "        a.append(file)\n",
    "        scores.append(a)\n",
    "        infile.close()\n",
    "              \n",
    "for score in scores:\n",
    "    print(\"Architektura: {} miałą acc na zbiorze testowym równe: {:.2f}\".format(score[-1],score[2]))\n",
    "#     tmp=[folder[0].split(\"-\")[-1].upper()]\n",
    "#     tmp.append([folder[0]+\"/\"+x for x in folder[2]])\n",
    "#     img_path.append(tmp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Jak widać powyższe rezultaty nie zachwycają, spróbujmy innego podejścia"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transfer learning\n",
    "\n",
    "Keras oferuje kilka wyuczonych wcześniej modeli:\n",
    "\n",
    "    Xception\n",
    "    VGG16\n",
    "    VGG19\n",
    "    ResNet, ResNetV2, ResNeXt\n",
    "    InceptionV3\n",
    "    InceptionResNetV2\n",
    "    MobileNet\n",
    "    MobileNetV2\n",
    "    DenseNet\n",
    "    NASNet\n",
    "\n",
    "Te modele bły przygotowywana na obrazkach od 224x224 pixeli do 299x299, ale keras pozwala trenować je obrazkami zaczynającymi się od 75x75. Z racji ograniczonej mocy obliczeniowej właśnie takie obrazki zastosuje\n",
    "\n",
    "Podejscie - będę uczył sieć w 2 fazach. W pierwszej wczytam wagi dla warstw konwolucyjnych, dodam warstwy ukryte niewyuczone warstwy ukryte. W drugiej wazie wykorzystam model model z pierwszej fazy ale odblokuje jeden lub dwa bloki warstw konwolucyjnych aby je douczyć ale ustawie oprimaizer tak by robił bardzo małe kroki"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/ralph/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    }
   ],
   "source": [
    "callbacks = [ \n",
    "    EarlyStopping(patience=3,monitor=\"val_loss\", restore_best_weights=True),\n",
    "    ReduceLROnPlateau(patience=2) # Gdy przez 2 epoki nie będzie poprawy zmniejszy LR o 10%\n",
    "]\n",
    "regularizer = l2(0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = Adam()\n",
    "base_model = VGG16(weights='imagenet', include_top=False, input_shape=image_shape)\n",
    "\n",
    "for layer in base_model.layers[1:]: \n",
    "    layer.trainable = False \n",
    "model, VGG16_arch1 = A.arch_TL_1(image_shape, num_classes, callbacks, train_generator, nb_train_samples*multiplier,\\\n",
    "                       validation_generator,nb_validation_samples,batch_size,test_generator,nb_test_samples,\\\n",
    "                      regularizer,optimizer, base_model)\n",
    "filename = '/home/ralph/ml/Sages/Zaliczenie/final/results/eval_VGG16_arch1'\n",
    "outfile = open(filename,'wb')\n",
    "pickle.dump(VGG16_arch1,outfile)\n",
    "outfile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Odblokowuje osttani blok konwolucji\n",
    "for layer in model.layers[0].layers[15:]: \n",
    "    layer.trainable = True\n",
    "  \n",
    "optimizer = Adam(0.00001, decay=0.00000001)\n",
    "\n",
    "# model.compile(loss='categorical_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
    "    \n",
    "# for layer in model.layers[0].layers:\n",
    "#     print(layer.name, layer.trainable)\n",
    "    \n",
    "# model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "vgg16 (Model)                (None, 2, 2, 512)         14714688  \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 128)               262272    \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 14,978,250\n",
      "Trainable params: 7,342,986\n",
      "Non-trainable params: 7,635,264\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "1595/1595 [==============================] - 62s 39ms/step - loss: 0.3003 - acc: 0.9344 - val_loss: 2.2634 - val_acc: 0.4909\n",
      "Epoch 2/100\n",
      "1595/1595 [==============================] - 60s 38ms/step - loss: 0.1920 - acc: 0.9675 - val_loss: 2.4088 - val_acc: 0.5455\n",
      "Epoch 3/100\n",
      "1595/1595 [==============================] - 60s 38ms/step - loss: 0.1387 - acc: 0.9824 - val_loss: 2.5367 - val_acc: 0.5636\n",
      "Epoch 4/100\n",
      "1595/1595 [==============================] - 60s 37ms/step - loss: 0.1737 - acc: 0.9689 - val_loss: 2.3316 - val_acc: 0.5864\n"
     ]
    }
   ],
   "source": [
    "model, VGG16_arch1_2 = A.TL_phase2(image_shape, num_classes, callbacks, train_generator, nb_train_samples*multiplier,\\\n",
    "                       validation_generator,nb_validation_samples,batch_size,test_generator,nb_test_samples,\\\n",
    "                      regularizer,optimizer, model)\n",
    "filename = '/home/ralph/ml/Sages/Zaliczenie/final/results/eval_VGG16_arch1_2'\n",
    "outfile = open(filename,'wb')\n",
    "pickle.dump(VGG16_arch1_2,outfile)\n",
    "outfile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "vgg16 (Model)                (None, 2, 2, 512)         14714688  \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 512)               1049088   \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 10)                5130      \n",
      "=================================================================\n",
      "Total params: 15,768,906\n",
      "Trainable params: 1,054,218\n",
      "Non-trainable params: 14,714,688\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "1595/1595 [==============================] - 51s 32ms/step - loss: 0.6703 - acc: 0.8462 - val_loss: 2.1255 - val_acc: 0.4591\n",
      "Epoch 2/100\n",
      "1595/1595 [==============================] - 48s 30ms/step - loss: 0.5783 - acc: 0.8811 - val_loss: 2.3319 - val_acc: 0.4364\n",
      "Epoch 3/100\n",
      "1595/1595 [==============================] - 48s 30ms/step - loss: 0.4702 - acc: 0.9158 - val_loss: 2.5359 - val_acc: 0.4727\n",
      "Epoch 4/100\n",
      "1595/1595 [==============================] - 48s 30ms/step - loss: 0.6021 - acc: 0.8623 - val_loss: 2.2858 - val_acc: 0.5000\n",
      "Epoch 1/100\n",
      "Epoch 1/100"
     ]
    }
   ],
   "source": [
    "# VGG16 druga architektura\n",
    "\n",
    "optimizer = Adam()\n",
    "regularizer = l2(0.0001)\n",
    "base_model = VGG16(weights='imagenet', include_top=False, input_shape=image_shape)\n",
    "\n",
    "for layer in base_model.layers[1:]: \n",
    "    layer.trainable = False \n",
    "model, VGG16_arch2 = A.arch_TL_2(image_shape, num_classes, callbacks, train_generator, nb_train_samples*multiplier,\\\n",
    "                       validation_generator,nb_validation_samples,batch_size,test_generator,nb_test_samples,\\\n",
    "                      regularizer,optimizer, base_model)\n",
    "filename = '/home/ralph/ml/Sages/Zaliczenie/final/results/eval_VGG16_arch2'\n",
    "outfile = open(filename,'wb')\n",
    "pickle.dump(VGG16_arch2,outfile)\n",
    "outfile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "vgg16 (Model)                (None, 2, 2, 512)         14714688  \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 512)               1049088   \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 10)                5130      \n",
      "=================================================================\n",
      "Total params: 15,768,906\n",
      "Trainable params: 8,133,642\n",
      "Non-trainable params: 7,635,264\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "1595/1595 [==============================] - 63s 40ms/step - loss: 0.3302 - acc: 0.9471 - val_loss: 2.4974 - val_acc: 0.5045\n",
      "Epoch 2/100\n",
      "1595/1595 [==============================] - 60s 38ms/step - loss: 0.2417 - acc: 0.9730 - val_loss: 2.3855 - val_acc: 0.5364\n",
      "Epoch 3/100\n",
      "1595/1595 [==============================] - 60s 38ms/step - loss: 0.1760 - acc: 0.9894 - val_loss: 2.7316 - val_acc: 0.5591\n",
      "Epoch 4/100\n",
      "1595/1595 [==============================] - 61s 38ms/step - loss: 0.1593 - acc: 0.9931 - val_loss: 2.6061 - val_acc: 0.5364\n",
      "Epoch 5/100\n",
      "1595/1595 [==============================] - 60s 38ms/step - loss: 0.1647 - acc: 0.9919 - val_loss: 2.6681 - val_acc: 0.5455\n",
      "Epoch 1/100\n"
     ]
    }
   ],
   "source": [
    "# VGG16 - druga faza\n",
    "# Odblokowuje ostatani blok konwolucji\n",
    "for layer in model.layers[0].layers[15:]: \n",
    "    layer.trainable = True\n",
    "   \n",
    "optimizer = Adam(0.00001, decay=0.00000001)\n",
    "\n",
    "model, VGG16_arch2_2 = A.TL_phase2(image_shape, num_classes, callbacks, train_generator, nb_train_samples*multiplier,\\\n",
    "                       validation_generator,nb_validation_samples,batch_size,test_generator,nb_test_samples,\\\n",
    "                      regularizer,optimizer, model)\n",
    "filename = '/home/ralph/ml/Sages/Zaliczenie/final/results/eval_VGG16_arch2_2'\n",
    "outfile = open(filename,'wb')\n",
    "pickle.dump(VGG16_arch2_2,outfile)\n",
    "outfile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "vgg16 (Model)                (None, 2, 2, 512)         14714688  \n",
      "_________________________________________________________________\n",
      "flatten_3 (Flatten)          (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 512)               1049088   \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 128)               65664     \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 15,830,730\n",
      "Trainable params: 1,116,042\n",
      "Non-trainable params: 14,714,688\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "1595/1595 [==============================] - 51s 32ms/step - loss: 1.0045 - acc: 0.7246 - val_loss: 2.1183 - val_acc: 0.4364\n",
      "Epoch 2/100\n",
      "1595/1595 [==============================] - 48s 30ms/step - loss: 0.7152 - acc: 0.8192 - val_loss: 2.6403 - val_acc: 0.4182\n",
      "Epoch 3/100\n",
      "1595/1595 [==============================] - 49s 30ms/step - loss: 0.5956 - acc: 0.8570 - val_loss: 2.3943 - val_acc: 0.4500\n",
      "Epoch 4/100\n",
      "1595/1595 [==============================] - 49s 31ms/step - loss: 0.7483 - acc: 0.8026 - val_loss: 2.0182 - val_acc: 0.5045\n",
      "Epoch 5/100\n",
      "1595/1595 [==============================] - 49s 31ms/step - loss: 0.6181 - acc: 0.8467 - val_loss: 2.1222 - val_acc: 0.4682\n",
      "Epoch 6/100\n",
      "1595/1595 [==============================] - 49s 31ms/step - loss: 0.5635 - acc: 0.8641 - val_loss: 2.1868 - val_acc: 0.5091\n",
      "Epoch 7/100\n",
      "1595/1595 [==============================] - 49s 31ms/step - loss: 0.6560 - acc: 0.8297 - val_loss: 2.1119 - val_acc: 0.5000\n"
     ]
    }
   ],
   "source": [
    "# VGG16 trzecia architektura\n",
    "optimizer = Adam()\n",
    "\n",
    "base_model = VGG16(weights='imagenet', include_top=False, input_shape=image_shape)\n",
    "\n",
    "for layer in base_model.layers[1:]: \n",
    "    layer.trainable = False \n",
    "model, VGG16_arch3 = A.arch_TL_3(image_shape, num_classes, callbacks, train_generator, nb_train_samples*multiplier,\\\n",
    "                       validation_generator,nb_validation_samples,batch_size,test_generator,nb_test_samples,\\\n",
    "                      regularizer,optimizer, base_model)\n",
    "filename = '/home/ralph/ml/Sages/Zaliczenie/final/results/eval_VGG16_arch3'\n",
    "outfile = open(filename,'wb')\n",
    "pickle.dump(VGG16_arch3,outfile)\n",
    "outfile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "vgg16 (Model)                (None, 2, 2, 512)         14714688  \n",
      "_________________________________________________________________\n",
      "flatten_3 (Flatten)          (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 512)               1049088   \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 128)               65664     \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 15,830,730\n",
      "Trainable params: 8,195,466\n",
      "Non-trainable params: 7,635,264\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "1595/1595 [==============================] - 65s 40ms/step - loss: 0.3564 - acc: 0.9348 - val_loss: 2.3702 - val_acc: 0.5409\n",
      "Epoch 2/100\n",
      "1595/1595 [==============================] - 61s 38ms/step - loss: 0.2479 - acc: 0.9673 - val_loss: 2.7730 - val_acc: 0.5455\n",
      "Epoch 3/100\n",
      "1595/1595 [==============================] - 61s 38ms/step - loss: 0.2074 - acc: 0.9799 - val_loss: 2.8403 - val_acc: 0.5227\n",
      "Epoch 4/100\n",
      "1595/1595 [==============================] - 61s 39ms/step - loss: 0.2622 - acc: 0.9596 - val_loss: 2.6040 - val_acc: 0.5500\n"
     ]
    }
   ],
   "source": [
    "# VGG16 - druga faza\n",
    "# Odblokowuje ostatani blok konwolucji\n",
    "for layer in model.layers[0].layers[15:]: \n",
    "    layer.trainable = True\n",
    "   \n",
    "optimizer = Adam(0.00001, decay=0.00000001)\n",
    "\n",
    "model, VGG16_arch3_2 = A.TL_phase2(image_shape, num_classes, callbacks, train_generator, nb_train_samples*multiplier,\\\n",
    "                       validation_generator,nb_validation_samples,batch_size,test_generator,nb_test_samples,\\\n",
    "                      regularizer,optimizer, model)\n",
    "filename = '/home/ralph/ml/Sages/Zaliczenie/final/results/eval_VGG16_arch3_2'\n",
    "outfile = open(filename,'wb')\n",
    "pickle.dump(VGG16_arch3_2,outfile)\n",
    "outfile.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### VGG19"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "vgg19 (Model)                (None, 2, 2, 512)         20024384  \n",
      "_________________________________________________________________\n",
      "flatten_4 (Flatten)          (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 128)               262272    \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 20,287,946\n",
      "Trainable params: 263,562\n",
      "Non-trainable params: 20,024,384\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "1595/1595 [==============================] - 54s 34ms/step - loss: 1.1895 - acc: 0.6304 - val_loss: 1.9459 - val_acc: 0.3682\n",
      "Epoch 2/100\n",
      "1595/1595 [==============================] - 51s 32ms/step - loss: 0.8428 - acc: 0.7569 - val_loss: 2.1599 - val_acc: 0.3818\n",
      "Epoch 3/100\n",
      "1595/1595 [==============================] - 51s 32ms/step - loss: 0.7162 - acc: 0.8011 - val_loss: 2.2940 - val_acc: 0.4545\n",
      "Epoch 4/100\n",
      "1595/1595 [==============================] - 51s 32ms/step - loss: 0.9217 - acc: 0.7185 - val_loss: 2.1036 - val_acc: 0.4909\n"
     ]
    }
   ],
   "source": [
    "optimizer = Adam()\n",
    "base_model = VGG19(weights='imagenet', include_top=False, input_shape=image_shape)\n",
    "\n",
    "for layer in base_model.layers[1:]: \n",
    "    layer.trainable = False \n",
    "model, VGG19_arch1 = A.arch_TL_1(image_shape, num_classes, callbacks, train_generator, nb_train_samples*multiplier,\\\n",
    "                       validation_generator,nb_validation_samples,batch_size,test_generator,nb_test_samples,\\\n",
    "                      regularizer,optimizer, base_model)\n",
    "filename = '/home/ralph/ml/Sages/Zaliczenie/final/results/eval_VGG19_arch1'\n",
    "outfile = open(filename,'wb')\n",
    "pickle.dump(VGG19_arch1,outfile)\n",
    "outfile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Odblokowuje ostatani blok konwolucji\n",
    "for layer in model.layers[0].layers[17:]: \n",
    "    layer.trainable = True\n",
    "  \n",
    "optimizer = Adam(0.00001, decay=0.00000001)\n",
    "\n",
    "# model.compile(loss='categorical_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
    "# for layer in model.layers[0].layers:\n",
    "#     print(layer.name, layer.trainable)\n",
    "# model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "vgg19 (Model)                (None, 2, 2, 512)         20024384  \n",
      "_________________________________________________________________\n",
      "flatten_4 (Flatten)          (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 128)               262272    \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 20,287,946\n",
      "Trainable params: 9,702,794\n",
      "Non-trainable params: 10,585,152\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "1595/1595 [==============================] - 75s 47ms/step - loss: 0.4229 - acc: 0.8939 - val_loss: 2.3502 - val_acc: 0.5091\n",
      "Epoch 2/100\n",
      "1595/1595 [==============================] - 71s 45ms/step - loss: 0.2296 - acc: 0.9550 - val_loss: 2.6751 - val_acc: 0.4909\n",
      "Epoch 3/100\n",
      "1595/1595 [==============================] - 71s 45ms/step - loss: 0.1339 - acc: 0.9810 - val_loss: 2.6788 - val_acc: 0.5591\n",
      "Epoch 4/100\n",
      "1595/1595 [==============================] - 71s 45ms/step - loss: 0.1608 - acc: 0.9690 - val_loss: 2.6386 - val_acc: 0.5591\n"
     ]
    }
   ],
   "source": [
    "model, VGG19_arch1_2 = A.TL_phase2(image_shape, num_classes, callbacks, train_generator, nb_train_samples*multiplier,\\\n",
    "                       validation_generator,nb_validation_samples,batch_size,test_generator,nb_test_samples,\\\n",
    "                      regularizer,optimizer, model)\n",
    "filename = '/home/ralph/ml/Sages/Zaliczenie/final/results/eval_VGG19_arch1_2'\n",
    "outfile = open(filename,'wb')\n",
    "pickle.dump(VGG19_arch1_2,outfile)\n",
    "outfile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dalej arch 2 i 3 do VGG19\n",
    "# a potem jeszcze ze 2-3 modele\n",
    "# Jak nie zadziła dobrze to wieksze obrazki na 1-2 modeli\n",
    "# potem we flasku implementacja najlepszego modelu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/ralph/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "vgg19 (Model)                (None, 2, 2, 512)         20024384  \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 512)               1049088   \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 10)                5130      \n",
      "=================================================================\n",
      "Total params: 21,078,602\n",
      "Trainable params: 1,054,218\n",
      "Non-trainable params: 20,024,384\n",
      "_________________________________________________________________\n",
      "WARNING:tensorflow:From /home/ralph/anaconda3/lib/python3.7/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Epoch 1/100\n",
      "1595/1595 [==============================] - 55s 34ms/step - loss: 0.9228 - acc: 0.7617 - val_loss: 2.2161 - val_acc: 0.4318\n",
      "Epoch 2/100\n",
      "1595/1595 [==============================] - 51s 32ms/step - loss: 0.6318 - acc: 0.8552 - val_loss: 2.1719 - val_acc: 0.4409\n",
      "Epoch 3/100\n",
      "1595/1595 [==============================] - 51s 32ms/step - loss: 0.5424 - acc: 0.8861 - val_loss: 2.1724 - val_acc: 0.4364\n",
      "Epoch 4/100\n",
      "1595/1595 [==============================] - 51s 32ms/step - loss: 0.4972 - acc: 0.8993 - val_loss: 2.4837 - val_acc: 0.4727\n",
      "Epoch 5/100\n",
      "1595/1595 [==============================] - 51s 32ms/step - loss: 0.6244 - acc: 0.8487 - val_loss: 2.2387 - val_acc: 0.4864\n"
     ]
    }
   ],
   "source": [
    "# Architektura 2\n",
    "optimizer = Adam()\n",
    "base_model = VGG19(weights='imagenet', include_top=False, input_shape=image_shape)\n",
    "\n",
    "for layer in base_model.layers[1:]: \n",
    "    layer.trainable = False \n",
    "model, VGG19_arch2 = A.arch_TL_2(image_shape, num_classes, callbacks, train_generator, nb_train_samples*multiplier,\\\n",
    "                       validation_generator,nb_validation_samples,batch_size,test_generator,nb_test_samples,\\\n",
    "                      regularizer,optimizer, base_model)\n",
    "filename = '/home/ralph/ml/Sages/Zaliczenie/final/results/eval_VGG19_arch2'\n",
    "outfile = open(filename,'wb')\n",
    "pickle.dump(VGG19_arch2,outfile)\n",
    "outfile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Odblokowuje ostatani blok konwolucji\n",
    "for layer in model.layers[0].layers[17:]: \n",
    "    layer.trainable = True\n",
    "  \n",
    "optimizer = Adam(0.00001, decay=0.00000001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "vgg19 (Model)                (None, 2, 2, 512)         20024384  \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 512)               1049088   \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 10)                5130      \n",
      "=================================================================\n",
      "Total params: 21,078,602\n",
      "Trainable params: 10,493,450\n",
      "Non-trainable params: 10,585,152\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "1595/1595 [==============================] - 74s 47ms/step - loss: 0.3796 - acc: 0.9336 - val_loss: 2.5112 - val_acc: 0.5455\n",
      "Epoch 2/100\n",
      "1595/1595 [==============================] - 71s 45ms/step - loss: 0.2148 - acc: 0.9827 - val_loss: 2.9587 - val_acc: 0.5000\n",
      "Epoch 3/100\n",
      "1595/1595 [==============================] - 71s 45ms/step - loss: 0.2001 - acc: 0.9869 - val_loss: 2.6748 - val_acc: 0.5045\n",
      "Epoch 4/100\n",
      "1595/1595 [==============================] - 71s 45ms/step - loss: 0.2237 - acc: 0.9776 - val_loss: 2.7093 - val_acc: 0.5591\n"
     ]
    }
   ],
   "source": [
    "model, VGG19_arch2_2 = A.TL_phase2(image_shape, num_classes, callbacks, train_generator, nb_train_samples*multiplier,\\\n",
    "                       validation_generator,nb_validation_samples,batch_size,test_generator,nb_test_samples,\\\n",
    "                      regularizer,optimizer, model)\n",
    "filename = '/home/ralph/ml/Sages/Zaliczenie/final/results/eval_VGG19_arch2_2'\n",
    "outfile = open(filename,'wb')\n",
    "pickle.dump(VGG19_arch2_2,outfile)\n",
    "outfile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "vgg19 (Model)                (None, 2, 2, 512)         20024384  \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 512)               1049088   \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 128)               65664     \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 21,140,426\n",
      "Trainable params: 1,116,042\n",
      "Non-trainable params: 20,024,384\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "1595/1595 [==============================] - 54s 34ms/step - loss: 1.1650 - acc: 0.6639 - val_loss: 2.0436 - val_acc: 0.4091\n",
      "Epoch 2/100\n",
      "1595/1595 [==============================] - 52s 32ms/step - loss: 0.9992 - acc: 0.7158 - val_loss: 2.1486 - val_acc: 0.4091\n",
      "Epoch 3/100\n",
      "1595/1595 [==============================] - 51s 32ms/step - loss: 0.8676 - acc: 0.7566 - val_loss: 2.1787 - val_acc: 0.4500\n",
      "Epoch 4/100\n",
      "1595/1595 [==============================] - 51s 32ms/step - loss: 1.0416 - acc: 0.6941 - val_loss: 1.9753 - val_acc: 0.4591\n",
      "Epoch 5/100\n",
      "1595/1595 [==============================] - 52s 32ms/step - loss: 0.8836 - acc: 0.7491 - val_loss: 1.9851 - val_acc: 0.4545\n",
      "Epoch 6/100\n",
      "1595/1595 [==============================] - 51s 32ms/step - loss: 0.8242 - acc: 0.7656 - val_loss: 2.0147 - val_acc: 0.4773\n",
      "Epoch 7/100\n",
      "1595/1595 [==============================] - 51s 32ms/step - loss: 0.8799 - acc: 0.7467 - val_loss: 1.9663 - val_acc: 0.4682\n",
      "Epoch 8/100\n",
      "1595/1595 [==============================] - 52s 32ms/step - loss: 0.8892 - acc: 0.7445 - val_loss: 1.9860 - val_acc: 0.4727\n",
      "Epoch 9/100\n",
      "1595/1595 [==============================] - 52s 32ms/step - loss: 0.8654 - acc: 0.7493 - val_loss: 1.9609 - val_acc: 0.4955\n",
      "Epoch 10/100\n",
      "1595/1595 [==============================] - 51s 32ms/step - loss: 0.8631 - acc: 0.7512 - val_loss: 2.0004 - val_acc: 0.4818\n",
      "Epoch 11/100\n",
      "1595/1595 [==============================] - 52s 32ms/step - loss: 0.8504 - acc: 0.7552 - val_loss: 2.0039 - val_acc: 0.4591\n",
      "Epoch 12/100\n",
      "1595/1595 [==============================] - 52s 32ms/step - loss: 0.8739 - acc: 0.7437 - val_loss: 1.9871 - val_acc: 0.4682\n"
     ]
    }
   ],
   "source": [
    "# Architektura 3\n",
    "optimizer = Adam()\n",
    "base_model = VGG19(weights='imagenet', include_top=False, input_shape=image_shape)\n",
    "\n",
    "for layer in base_model.layers[1:]: \n",
    "    layer.trainable = False \n",
    "model, VGG19_arch3 = A.arch_TL_3(image_shape, num_classes, callbacks, train_generator, nb_train_samples*multiplier,\\\n",
    "                       validation_generator,nb_validation_samples,batch_size,test_generator,nb_test_samples,\\\n",
    "                      regularizer,optimizer, base_model)\n",
    "filename = '/home/ralph/ml/Sages/Zaliczenie/final/results/eval_VGG19_arch3'\n",
    "outfile = open(filename,'wb')\n",
    "pickle.dump(VGG19_arch3,outfile)\n",
    "outfile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Odblokowuje ostatani blok konwolucji\n",
    "for layer in model.layers[0].layers[17:]: \n",
    "    layer.trainable = True\n",
    "  \n",
    "optimizer = Adam(0.00001, decay=0.00000001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "vgg19 (Model)                (None, 2, 2, 512)         20024384  \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 512)               1049088   \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 128)               65664     \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 21,140,426\n",
      "Trainable params: 10,555,274\n",
      "Non-trainable params: 10,585,152\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "1595/1595 [==============================] - 76s 48ms/step - loss: 0.4056 - acc: 0.9108 - val_loss: 2.4047 - val_acc: 0.5045\n",
      "Epoch 2/100\n",
      "1595/1595 [==============================] - 73s 46ms/step - loss: 0.2864 - acc: 0.9484 - val_loss: 2.5025 - val_acc: 0.5091\n",
      "Epoch 3/100\n",
      "1595/1595 [==============================] - 73s 46ms/step - loss: 0.2126 - acc: 0.9702 - val_loss: 2.8701 - val_acc: 0.4955\n",
      "Epoch 4/100\n",
      "1595/1595 [==============================] - 74s 46ms/step - loss: 0.2484 - acc: 0.9561 - val_loss: 2.4846 - val_acc: 0.5455\n"
     ]
    }
   ],
   "source": [
    "model, VGG19_arch3_2 = A.TL_phase2(image_shape, num_classes, callbacks, train_generator, nb_train_samples*multiplier,\\\n",
    "                       validation_generator,nb_validation_samples,batch_size,test_generator,nb_test_samples,\\\n",
    "                      regularizer,optimizer, model)\n",
    "filename = '/home/ralph/ml/Sages/Zaliczenie/final/results/eval_VGG19_arch3_2'\n",
    "outfile = open(filename,'wb')\n",
    "pickle.dump(VGG19_arch3_2,outfile)\n",
    "outfile.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Xception"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "xception (Model)             (None, 3, 3, 2048)        20861480  \n",
      "_________________________________________________________________\n",
      "flatten_3 (Flatten)          (None, 18432)             0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 128)               2359424   \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 23,222,194\n",
      "Trainable params: 2,360,714\n",
      "Non-trainable params: 20,861,480\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "1595/1595 [==============================] - 55s 34ms/step - loss: 0.9574 - acc: 0.7636 - val_loss: 3.4343 - val_acc: 0.4273\n",
      "Epoch 2/100\n",
      "1595/1595 [==============================] - 49s 31ms/step - loss: 0.8491 - acc: 0.8041 - val_loss: 3.6803 - val_acc: 0.4636\n",
      "Epoch 3/100\n",
      "1595/1595 [==============================] - 50s 31ms/step - loss: 0.8796 - acc: 0.8026 - val_loss: 3.4108 - val_acc: 0.4500\n",
      "Epoch 4/100\n",
      "1595/1595 [==============================] - 49s 31ms/step - loss: 0.9187 - acc: 0.8021 - val_loss: 4.4128 - val_acc: 0.4591\n",
      "Epoch 5/100\n",
      "1595/1595 [==============================] - 48s 30ms/step - loss: 0.8862 - acc: 0.8130 - val_loss: 3.7418 - val_acc: 0.4864\n",
      "Epoch 6/100\n",
      "1595/1595 [==============================] - 50s 31ms/step - loss: 1.2148 - acc: 0.6915 - val_loss: 4.0123 - val_acc: 0.4955\n"
     ]
    }
   ],
   "source": [
    "optimizer = Adam()\n",
    "base_model = Xception(weights='imagenet', include_top=False, input_shape=image_shape)\n",
    "\n",
    "for layer in base_model.layers[1:]: \n",
    "    layer.trainable = False \n",
    "model, Xception_arch1 = A.arch_TL_1(image_shape, num_classes, callbacks, train_generator, nb_train_samples*multiplier,\\\n",
    "                       validation_generator,nb_validation_samples,batch_size,test_generator,nb_test_samples,\\\n",
    "                      regularizer,optimizer, base_model)\n",
    "filename = '/home/ralph/ml/Sages/Zaliczenie/final/results/eval_Xception_arch1'\n",
    "outfile = open(filename,'wb')\n",
    "pickle.dump(Xception_arch1,outfile)\n",
    "outfile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Odblokowuje ostatani blok konwolucji\n",
    "for layer in model.layers[0].layers[-6:]: \n",
    "    layer.trainable = True\n",
    "  \n",
    "optimizer = Adam(0.00001, decay=0.00000001)\n",
    "\n",
    "# model.compile(loss='categorical_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
    "# for layer in model.layers[0].layers:\n",
    "#     print(layer.name, layer.trainable)\n",
    "# model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "xception (Model)             (None, 3, 3, 2048)        20861480  \n",
      "_________________________________________________________________\n",
      "flatten_3 (Flatten)          (None, 18432)             0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 128)               2359424   \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 23,222,194\n",
      "Trainable params: 7,109,514\n",
      "Non-trainable params: 16,112,680\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "1595/1595 [==============================] - 62s 39ms/step - loss: 1.0880 - acc: 0.7173 - val_loss: 3.5286 - val_acc: 0.4864\n",
      "Epoch 2/100\n",
      "1595/1595 [==============================] - 56s 35ms/step - loss: 0.7219 - acc: 0.8386 - val_loss: 4.0491 - val_acc: 0.4682\n",
      "Epoch 3/100\n",
      "1595/1595 [==============================] - 56s 35ms/step - loss: 0.4800 - acc: 0.9201 - val_loss: 4.2683 - val_acc: 0.4591\n",
      "Epoch 4/100\n",
      "1595/1595 [==============================] - 56s 35ms/step - loss: 1.3591 - acc: 0.6768 - val_loss: 4.1105 - val_acc: 0.4636\n"
     ]
    }
   ],
   "source": [
    "model, VGG19_arch1_2 = A.TL_phase2(image_shape, num_classes, callbacks, train_generator, nb_train_samples*multiplier,\\\n",
    "                       validation_generator,nb_validation_samples,batch_size,test_generator,nb_test_samples,\\\n",
    "                      regularizer,optimizer, model)\n",
    "filename = '/home/ralph/ml/Sages/Zaliczenie/final/results/eval_VGG19_arch1_2'\n",
    "outfile = open(filename,'wb')\n",
    "pickle.dump(VGG19_arch1_2,outfile)\n",
    "outfile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "xception (Model)             (None, 3, 3, 2048)        20861480  \n",
      "_________________________________________________________________\n",
      "flatten_4 (Flatten)          (None, 18432)             0         \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 512)               9437696   \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 10)                5130      \n",
      "=================================================================\n",
      "Total params: 30,304,306\n",
      "Trainable params: 9,442,826\n",
      "Non-trainable params: 20,861,480\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "1595/1595 [==============================] - 63s 39ms/step - loss: 1.2759 - acc: 0.8318 - val_loss: 5.1311 - val_acc: 0.4182\n",
      "Epoch 2/100\n",
      "1595/1595 [==============================] - 56s 35ms/step - loss: 0.8153 - acc: 0.8884 - val_loss: 4.8601 - val_acc: 0.4091\n",
      "Epoch 3/100\n",
      "1595/1595 [==============================] - 56s 35ms/step - loss: 0.8412 - acc: 0.8850 - val_loss: 3.4011 - val_acc: 0.4955\n",
      "Epoch 4/100\n",
      "1595/1595 [==============================] - 57s 35ms/step - loss: 0.8595 - acc: 0.8789 - val_loss: 5.6216 - val_acc: 0.3727\n",
      "Epoch 5/100\n",
      "1595/1595 [==============================] - 57s 36ms/step - loss: 0.8983 - acc: 0.8678 - val_loss: 3.4520 - val_acc: 0.4545\n",
      "Epoch 6/100\n",
      "1595/1595 [==============================] - 56s 35ms/step - loss: 1.0558 - acc: 0.8061 - val_loss: 3.8468 - val_acc: 0.4864\n"
     ]
    }
   ],
   "source": [
    "# Architektura 2\n",
    "optimizer = Adam()\n",
    "base_model = Xception(weights='imagenet', include_top=False, input_shape=image_shape)\n",
    "\n",
    "for layer in base_model.layers[1:]: \n",
    "    layer.trainable = False \n",
    "model, Xception_arch2 = A.arch_TL_2(image_shape, num_classes, callbacks, train_generator, nb_train_samples*multiplier,\\\n",
    "                       validation_generator,nb_validation_samples,batch_size,test_generator,nb_test_samples,\\\n",
    "                      regularizer,optimizer, base_model)\n",
    "filename = '/home/ralph/ml/Sages/Zaliczenie/final/results/eval_Xception_arch2'\n",
    "outfile = open(filename,'wb')\n",
    "pickle.dump(Xception_arch2,outfile)\n",
    "outfile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Odblokowuje ostatani blok konwolucji\n",
    "for layer in model.layers[0].layers[-6:]: \n",
    "    layer.trainable = True\n",
    "  \n",
    "optimizer = Adam(0.00001, decay=0.00000001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "xception (Model)             (None, 3, 3, 2048)        20861480  \n",
      "_________________________________________________________________\n",
      "flatten_4 (Flatten)          (None, 18432)             0         \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 512)               9437696   \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 10)                5130      \n",
      "=================================================================\n",
      "Total params: 30,304,306\n",
      "Trainable params: 14,191,626\n",
      "Non-trainable params: 16,112,680\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "1595/1595 [==============================] - 72s 45ms/step - loss: 1.1868 - acc: 0.7405 - val_loss: 3.3447 - val_acc: 0.4955\n",
      "Epoch 2/100\n",
      "1595/1595 [==============================] - 66s 41ms/step - loss: 0.7504 - acc: 0.8745 - val_loss: 3.5018 - val_acc: 0.5136\n",
      "Epoch 3/100\n",
      "1595/1595 [==============================] - 66s 41ms/step - loss: 0.4617 - acc: 0.9612 - val_loss: 3.6387 - val_acc: 0.4955\n",
      "Epoch 4/100\n",
      "1595/1595 [==============================] - 65s 41ms/step - loss: 1.2354 - acc: 0.7251 - val_loss: 3.5627 - val_acc: 0.5045\n"
     ]
    }
   ],
   "source": [
    "model, Xception_arch2_2 = A.TL_phase2(image_shape, num_classes, callbacks, train_generator, nb_train_samples*multiplier,\\\n",
    "                       validation_generator,nb_validation_samples,batch_size,test_generator,nb_test_samples,\\\n",
    "                      regularizer,optimizer, model)\n",
    "filename = '/home/ralph/ml/Sages/Zaliczenie/final/results/eval_Xception_arch2_2'\n",
    "outfile = open(filename,'wb')\n",
    "pickle.dump(Xception_arch2_2,outfile)\n",
    "outfile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "xception (Model)             (None, 3, 3, 2048)        20861480  \n",
      "_________________________________________________________________\n",
      "flatten_5 (Flatten)          (None, 18432)             0         \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 512)               9437696   \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 128)               65664     \n",
      "_________________________________________________________________\n",
      "dropout_7 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 30,366,130\n",
      "Trainable params: 9,504,650\n",
      "Non-trainable params: 20,861,480\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "1595/1595 [==============================] - 65s 41ms/step - loss: 1.0996 - acc: 0.7670 - val_loss: 3.4640 - val_acc: 0.4091\n",
      "Epoch 2/100\n",
      "1595/1595 [==============================] - 57s 36ms/step - loss: 1.0414 - acc: 0.7830 - val_loss: 3.4591 - val_acc: 0.4182\n",
      "Epoch 3/100\n",
      "1595/1595 [==============================] - 57s 36ms/step - loss: 1.1620 - acc: 0.7525 - val_loss: 3.6401 - val_acc: 0.4500\n",
      "Epoch 4/100\n",
      "1595/1595 [==============================] - 57s 36ms/step - loss: 1.1357 - acc: 0.7645 - val_loss: 3.2975 - val_acc: 0.4182\n",
      "Epoch 5/100\n",
      "1595/1595 [==============================] - 57s 36ms/step - loss: 1.1498 - acc: 0.7685 - val_loss: 4.2777 - val_acc: 0.4227\n",
      "Epoch 6/100\n",
      "1595/1595 [==============================] - 57s 36ms/step - loss: 1.1183 - acc: 0.7819 - val_loss: 4.1088 - val_acc: 0.4455\n",
      "Epoch 7/100\n",
      "1595/1595 [==============================] - 58s 36ms/step - loss: 1.2300 - acc: 0.7288 - val_loss: 3.9976 - val_acc: 0.4773\n"
     ]
    }
   ],
   "source": [
    "# Architektura 3\n",
    "optimizer = Adam()\n",
    "base_model = Xception(weights='imagenet', include_top=False, input_shape=image_shape)\n",
    "\n",
    "for layer in base_model.layers[1:]: \n",
    "    layer.trainable = False \n",
    "model, Xception_arch3 = A.arch_TL_3(image_shape, num_classes, callbacks, train_generator, nb_train_samples*multiplier,\\\n",
    "                       validation_generator,nb_validation_samples,batch_size,test_generator,nb_test_samples,\\\n",
    "                      regularizer,optimizer, base_model)\n",
    "filename = '/home/ralph/ml/Sages/Zaliczenie/final/results/eval_Xception_arch3'\n",
    "outfile = open(filename,'wb')\n",
    "pickle.dump(Xception_arch3,outfile)\n",
    "outfile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Odblokowuje ostatani blok konwolucji\n",
    "for layer in model.layers[0].layers[-6:]: \n",
    "    layer.trainable = True\n",
    "  \n",
    "optimizer = Adam(0.00001, decay=0.00000001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "xception (Model)             (None, 3, 3, 2048)        20861480  \n",
      "_________________________________________________________________\n",
      "flatten_5 (Flatten)          (None, 18432)             0         \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 512)               9437696   \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 128)               65664     \n",
      "_________________________________________________________________\n",
      "dropout_7 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 30,366,130\n",
      "Trainable params: 14,253,450\n",
      "Non-trainable params: 16,112,680\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "1595/1595 [==============================] - 77s 48ms/step - loss: 1.3952 - acc: 0.6603 - val_loss: 3.1371 - val_acc: 0.4591\n",
      "Epoch 2/100\n",
      "1595/1595 [==============================] - 68s 42ms/step - loss: 0.9920 - acc: 0.7774 - val_loss: 3.1298 - val_acc: 0.4864\n",
      "Epoch 3/100\n",
      "1595/1595 [==============================] - 68s 43ms/step - loss: 0.7219 - acc: 0.8664 - val_loss: 3.2915 - val_acc: 0.5182\n",
      "Epoch 4/100\n",
      "1595/1595 [==============================] - 68s 43ms/step - loss: 0.5683 - acc: 0.9136 - val_loss: 3.1955 - val_acc: 0.5500\n",
      "Epoch 5/100\n",
      "1595/1595 [==============================] - 68s 42ms/step - loss: 1.2346 - acc: 0.7256 - val_loss: 3.0651 - val_acc: 0.5409\n",
      "Epoch 6/100\n",
      "1595/1595 [==============================] - 68s 43ms/step - loss: 1.2379 - acc: 0.7278 - val_loss: 2.9678 - val_acc: 0.5500\n",
      "Epoch 7/100\n",
      "1595/1595 [==============================] - 68s 43ms/step - loss: 1.2165 - acc: 0.7195 - val_loss: 2.9283 - val_acc: 0.5409\n",
      "Epoch 8/100\n",
      "1595/1595 [==============================] - 68s 43ms/step - loss: 1.1866 - acc: 0.7293 - val_loss: 2.9254 - val_acc: 0.5409\n",
      "Epoch 9/100\n",
      "1595/1595 [==============================] - 68s 43ms/step - loss: 1.1485 - acc: 0.7333 - val_loss: 2.9041 - val_acc: 0.5409\n",
      "Epoch 10/100\n",
      "1595/1595 [==============================] - 68s 43ms/step - loss: 1.1490 - acc: 0.7431 - val_loss: 2.8404 - val_acc: 0.5500\n",
      "Epoch 11/100\n",
      "1595/1595 [==============================] - 68s 43ms/step - loss: 1.1267 - acc: 0.7417 - val_loss: 2.8438 - val_acc: 0.5682\n",
      "Epoch 12/100\n",
      "1595/1595 [==============================] - 68s 43ms/step - loss: 1.1039 - acc: 0.7446 - val_loss: 2.8701 - val_acc: 0.5591\n",
      "Epoch 13/100\n",
      "1595/1595 [==============================] - 68s 43ms/step - loss: 1.1877 - acc: 0.7284 - val_loss: 2.8636 - val_acc: 0.5591\n",
      "Epoch 1/100Epoch 1/100"
     ]
    }
   ],
   "source": [
    "model, Xception_arch3_2 = A.TL_phase2(image_shape, num_classes, callbacks, train_generator, nb_train_samples*multiplier,\\\n",
    "                       validation_generator,nb_validation_samples,batch_size,test_generator,nb_test_samples,\\\n",
    "                      regularizer,optimizer, model)\n",
    "filename = '/home/ralph/ml/Sages/Zaliczenie/final/results/eval_Xception_arch3_2'\n",
    "outfile = open(filename,'wb')\n",
    "pickle.dump(Xception_arch3_2,outfile)\n",
    "outfile.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sprawdźmy który z modeli sprawuję się najlepiej"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Architektura: eval_arch_6 miałą acc na zbiorze testowym równe: 0.08\n",
      "Architektura: eval_arch_8 miałą acc na zbiorze testowym równe: 0.09\n",
      "Architektura: eval_arch_7 miałą acc na zbiorze testowym równe: 0.09\n",
      "Architektura: eval_arch_9 miałą acc na zbiorze testowym równe: 0.10\n",
      "Architektura: eval_arch_4 miałą acc na zbiorze testowym równe: 0.10\n",
      "Architektura: eval_arch_3 miałą acc na zbiorze testowym równe: 0.10\n",
      "Architektura: eval_arch_10 miałą acc na zbiorze testowym równe: 0.11\n",
      "Architektura: eval_arch_5 miałą acc na zbiorze testowym równe: 0.11\n",
      "Architektura: eval_arch_1 miałą acc na zbiorze testowym równe: 0.30\n",
      "Architektura: eval_arch_2 miałą acc na zbiorze testowym równe: 0.39\n",
      "Architektura: eval_VGG16_arch1 miałą acc na zbiorze testowym równe: 0.41\n",
      "Architektura: eval_VGG16_arch2 miałą acc na zbiorze testowym równe: 0.42\n",
      "Architektura: eval_Xception_arch3 miałą acc na zbiorze testowym równe: 0.43\n",
      "Architektura: eval_VGG19_arch1 miałą acc na zbiorze testowym równe: 0.43\n",
      "Architektura: eval_VGG19_arch2 miałą acc na zbiorze testowym równe: 0.45\n",
      "Architektura: eval_VGG19_arch3 miałą acc na zbiorze testowym równe: 0.46\n",
      "Architektura: eval_VGG19_arch1_2 miałą acc na zbiorze testowym równe: 0.46\n",
      "Architektura: eval_VGG19_arch3_2 miałą acc na zbiorze testowym równe: 0.47\n",
      "Architektura: eval_Xception_arch1 miałą acc na zbiorze testowym równe: 0.47\n",
      "Architektura: eval_VGG16_arch2_2 miałą acc na zbiorze testowym równe: 0.49\n",
      "Architektura: eval_VGG16_arch3 miałą acc na zbiorze testowym równe: 0.50\n",
      "Architektura: eval_VGG16_arch3_2 miałą acc na zbiorze testowym równe: 0.50\n",
      "Architektura: eval_VGG19_arch2_2 miałą acc na zbiorze testowym równe: 0.50\n",
      "Architektura: eval_Xception_arch2 miałą acc na zbiorze testowym równe: 0.52\n",
      "Architektura: eval_VGG16_arch1_2 miałą acc na zbiorze testowym równe: 0.52\n",
      "Architektura: eval_Xception_arch3_2 miałą acc na zbiorze testowym równe: 0.52\n",
      "Architektura: eval_Xception_arch2_2 miałą acc na zbiorze testowym równe: 0.54\n"
     ]
    }
   ],
   "source": [
    "scores=[]\n",
    "\n",
    "for folder in os.walk('/home/ralph/ml/Sages/Zaliczenie/final/results'):\n",
    "    for file in folder[2]:\n",
    "        filename = '/home/ralph/ml/Sages/Zaliczenie/final/results/' + file\n",
    "        infile = open(filename,'rb')\n",
    "        a=pickle.load(infile)\n",
    "        a.append(file)\n",
    "        scores.append(a)\n",
    "        infile.close()\n",
    "              \n",
    "# print(scores)\n",
    "            \n",
    "def getKey(item):\n",
    "    return item[2]\n",
    "scores = sorted(scores, key=getKey)    \n",
    "        \n",
    "for score in scores:\n",
    "    print(\"Architektura: {} miałą acc na zbiorze testowym równe: {:.2f}\".format(score[-1],score[2]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wydaje się że na obrazkach w rozmiarze 75x75 nie mogę przekroczyć 55%. Uczenie sieci neuronowej zbudowanej na włąsnej aruchitekturze doprowadziło mnie jedynie do 39% skuteczności, a wykorzystanie metody transfer learningu na modelu Xception z 2 Fazowym uczeniem pozwoliło na uzyskanie 54% skuteczności. \n",
    "\n",
    "Spróbuję douczyć całą sieć Xception w tym celu odblokuje wszystkie warstwy, a jeśli wynik nie będzie zadowalający zacznę trenować sici na obrazkach większych rozmiarów. Z doswiadczenia już wiem że obrazki 224x224 pozwalają mi na wykorzystanie modelu VGG16 ale przy bardziej złożonych modelach mój komputer zgłasza koniec zasobów, wypróbuję więc obrazki w rozmiarze 150x150."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "xception (Model)             (None, 3, 3, 2048)        20861480  \n",
      "_________________________________________________________________\n",
      "flatten_6 (Flatten)          (None, 18432)             0         \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 512)               9437696   \n",
      "_________________________________________________________________\n",
      "dropout_8 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 10)                5130      \n",
      "=================================================================\n",
      "Total params: 30,304,306\n",
      "Trainable params: 30,249,778\n",
      "Non-trainable params: 54,528\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "1595/1595 [==============================] - 193s 121ms/step - loss: 1.1806 - acc: 0.8241 - val_loss: 14.6117 - val_acc: 0.0955\n",
      "Epoch 2/100\n",
      "1595/1595 [==============================] - 180s 113ms/step - loss: 1.2522 - acc: 0.8089 - val_loss: 3.7344 - val_acc: 0.2864\n",
      "Epoch 3/100\n",
      "1595/1595 [==============================] - 181s 113ms/step - loss: 1.1870 - acc: 0.8618 - val_loss: 3.6713 - val_acc: 0.3000\n",
      "Epoch 4/100\n",
      "1595/1595 [==============================] - 182s 114ms/step - loss: 1.0460 - acc: 0.8961 - val_loss: 4.2779 - val_acc: 0.3182\n",
      "Epoch 5/100\n",
      "1595/1595 [==============================] - 182s 114ms/step - loss: 0.9608 - acc: 0.9183 - val_loss: 2.8682 - val_acc: 0.3864\n",
      "Epoch 6/100\n",
      "1595/1595 [==============================] - 183s 115ms/step - loss: 0.8146 - acc: 0.9328 - val_loss: 2.7884 - val_acc: 0.4636\n",
      "Epoch 7/100\n",
      "1595/1595 [==============================] - 184s 115ms/step - loss: 0.7521 - acc: 0.9369 - val_loss: 3.0965 - val_acc: 0.4409\n",
      "Epoch 8/100\n",
      "1595/1595 [==============================] - 184s 116ms/step - loss: 0.7210 - acc: 0.9418 - val_loss: 2.6903 - val_acc: 0.4682\n",
      "Epoch 9/100\n",
      "1595/1595 [==============================] - 185s 116ms/step - loss: 0.6476 - acc: 0.9490 - val_loss: 2.7319 - val_acc: 0.4773\n",
      "Epoch 10/100\n",
      "1595/1595 [==============================] - 186s 117ms/step - loss: 0.6454 - acc: 0.9493 - val_loss: 2.3492 - val_acc: 0.4909\n",
      "Epoch 11/100\n",
      "1595/1595 [==============================] - 186s 117ms/step - loss: 0.6514 - acc: 0.9500 - val_loss: 3.3496 - val_acc: 0.4045\n",
      "Epoch 12/100\n",
      "1595/1595 [==============================] - 186s 117ms/step - loss: 0.6750 - acc: 0.9469 - val_loss: 2.6952 - val_acc: 0.4773\n",
      "Epoch 13/100\n",
      "1595/1595 [==============================] - 187s 117ms/step - loss: 0.6303 - acc: 0.9533 - val_loss: 3.3381 - val_acc: 0.4864\n",
      "Epoch 1/100\n"
     ]
    }
   ],
   "source": [
    "# Architektura 2\n",
    "optimizer = Adam()\n",
    "base_model = Xception(weights='imagenet', include_top=False, input_shape=image_shape)\n",
    "\n",
    "for layer in base_model.layers[1:]: \n",
    "    layer.trainable = True \n",
    "model, Xception_all_arch2 = A.arch_TL_2(image_shape, num_classes, callbacks, train_generator, nb_train_samples*multiplier,\\\n",
    "                       validation_generator,nb_validation_samples,batch_size,test_generator,nb_test_samples,\\\n",
    "                      regularizer,optimizer, base_model)\n",
    "filename = '/home/ralph/ml/Sages/Zaliczenie/final/results/eval_Xception_all_arch2'\n",
    "outfile = open(filename,'wb')\n",
    "pickle.dump(Xception_all_arch2,outfile)\n",
    "outfile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Architektura: eval_arch_6 miałą acc na zbiorze testowym równe: 0.08\n",
      "Architektura: eval_arch_8 miałą acc na zbiorze testowym równe: 0.09\n",
      "Architektura: eval_arch_7 miałą acc na zbiorze testowym równe: 0.09\n",
      "Architektura: eval_arch_9 miałą acc na zbiorze testowym równe: 0.10\n",
      "Architektura: eval_arch_4 miałą acc na zbiorze testowym równe: 0.10\n",
      "Architektura: eval_arch_3 miałą acc na zbiorze testowym równe: 0.10\n",
      "Architektura: eval_arch_10 miałą acc na zbiorze testowym równe: 0.11\n",
      "Architektura: eval_arch_5 miałą acc na zbiorze testowym równe: 0.11\n",
      "Architektura: eval_arch_1 miałą acc na zbiorze testowym równe: 0.30\n",
      "Architektura: eval_arch_2 miałą acc na zbiorze testowym równe: 0.39\n",
      "Architektura: eval_VGG16_arch1 miałą acc na zbiorze testowym równe: 0.41\n",
      "Architektura: eval_VGG16_arch2 miałą acc na zbiorze testowym równe: 0.42\n",
      "Architektura: eval_Xception_arch3 miałą acc na zbiorze testowym równe: 0.43\n",
      "Architektura: eval_VGG19_arch1 miałą acc na zbiorze testowym równe: 0.43\n",
      "Architektura: eval_VGG19_arch2 miałą acc na zbiorze testowym równe: 0.45\n",
      "Architektura: eval_VGG19_arch3 miałą acc na zbiorze testowym równe: 0.46\n",
      "Architektura: eval_VGG19_arch1_2 miałą acc na zbiorze testowym równe: 0.46\n",
      "Architektura: eval_VGG19_arch3_2 miałą acc na zbiorze testowym równe: 0.47\n",
      "Architektura: eval_Xception_arch1 miałą acc na zbiorze testowym równe: 0.47\n",
      "Architektura: eval_Xception_all_arch2 miałą acc na zbiorze testowym równe: 0.48\n",
      "Architektura: eval_VGG16_arch2_2 miałą acc na zbiorze testowym równe: 0.49\n",
      "Architektura: eval_VGG16_arch3 miałą acc na zbiorze testowym równe: 0.50\n",
      "Architektura: eval_VGG16_arch3_2 miałą acc na zbiorze testowym równe: 0.50\n",
      "Architektura: eval_VGG19_arch2_2 miałą acc na zbiorze testowym równe: 0.50\n",
      "Architektura: eval_Xception_arch2 miałą acc na zbiorze testowym równe: 0.52\n",
      "Architektura: eval_VGG16_arch1_2 miałą acc na zbiorze testowym równe: 0.52\n",
      "Architektura: eval_Xception_arch3_2 miałą acc na zbiorze testowym równe: 0.52\n",
      "Architektura: eval_Xception_arch2_2 miałą acc na zbiorze testowym równe: 0.54\n"
     ]
    }
   ],
   "source": [
    "scores=[]\n",
    "\n",
    "for folder in os.walk('/home/ralph/ml/Sages/Zaliczenie/final/results'):\n",
    "    for file in folder[2]:\n",
    "        filename = '/home/ralph/ml/Sages/Zaliczenie/final/results/' + file\n",
    "        infile = open(filename,'rb')\n",
    "        a=pickle.load(infile)\n",
    "        a.append(file)\n",
    "        scores.append(a)\n",
    "        infile.close()\n",
    "              \n",
    "# print(scores)\n",
    "            \n",
    "def getKey(item):\n",
    "    return item[2]\n",
    "scores = sorted(scores, key=getKey)    \n",
    "        \n",
    "for score in scores:\n",
    "    print(\"Architektura: {} miałą acc na zbiorze testowym równe: {:.2f}\".format(score[-1],score[2]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Jak widzimy mimo trenowania całego modelu nie doszlismy nawet do tak dobrego wyniku, spróbuję teraz innego podejscia\n",
    "\n",
    "### VGG16 na 224x224\n",
    "\n",
    "Model będzie sie bardzo długo uczył, a z prac testowych wiem że 2 warstwowa sieć zadziałą tu najlepiej, dlatego uruchomię tylko architekturę 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1276 images belonging to 10 classes.\n",
      "Found 220 images belonging to 10 classes.\n",
      "Found 203 images belonging to 10 classes.\n"
     ]
    }
   ],
   "source": [
    "train_data_dir = '/home/ralph/ml/Sages/Zaliczenie/Wybrane/train/'\n",
    "validation_data_dir = '/home/ralph/ml/Sages/Zaliczenie/Wybrane/validate/'\n",
    "test_data_dir = '/home/ralph/ml/Sages/Zaliczenie/Wybrane/test/'\n",
    "\n",
    "multiplier = 40 # 40 razy więcej obrazków wybierzemy z data generatora\n",
    "batch_size = 32\n",
    "w=224\n",
    "h=224\n",
    "\n",
    "train_datagen = ImageDataGenerator(rescale=1./255,\n",
    "                                shear_range=0.2,\n",
    "                                zoom_range=0.2,\n",
    "                                rotation_range=30,\n",
    "                                horizontal_flip=True)\n",
    "validation_datagen = ImageDataGenerator(rescale=1./255)\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(train_data_dir,\n",
    "                                                    target_size=(h, w),\n",
    "                                                    batch_size=batch_size, \n",
    "                                                    class_mode='categorical',\n",
    "                                                       shuffle=True)\n",
    "validation_generator = validation_datagen.flow_from_directory(validation_data_dir,\n",
    "                                                        target_size=(h, w),\n",
    "                                                        batch_size=220, # liczba wszystkich obrazków w zbiorze\n",
    "                                                        class_mode='categorical',\n",
    "                                                       shuffle=False)\n",
    "test_generator = test_datagen.flow_from_directory(test_data_dir,\n",
    "                                                        target_size=(h, w),\n",
    "                                                        batch_size=203, # liczba wszystkich obrazków w zbiorze\n",
    "                                                        class_mode='categorical',\n",
    "                                                        shuffle=False)\n",
    "\n",
    "num_classes = train_generator.num_classes\n",
    "image_shape = train_generator.image_shape\n",
    "\n",
    "nb_train_samples = train_generator.n\n",
    "nb_validation_samples = validation_generator.n\n",
    "nb_test_samples = test_generator.n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/ralph/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "vgg16 (Model)                (None, 7, 7, 512)         14714688  \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 25088)             0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 512)               12845568  \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 128)               65664     \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 27,627,210\n",
      "Trainable params: 12,912,522\n",
      "Non-trainable params: 14,714,688\n",
      "_________________________________________________________________\n",
      "WARNING:tensorflow:From /home/ralph/anaconda3/lib/python3.7/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Epoch 1/100\n",
      "1595/1595 [==============================] - 411s 258ms/step - loss: 0.8992 - acc: 0.7422 - val_loss: 1.3757 - val_acc: 0.6409\n",
      "Epoch 2/100\n",
      "1595/1595 [==============================] - 393s 246ms/step - loss: 0.5782 - acc: 0.8443 - val_loss: 1.2718 - val_acc: 0.6818\n",
      "Epoch 3/100\n",
      "1595/1595 [==============================] - 396s 248ms/step - loss: 0.5141 - acc: 0.8689 - val_loss: 1.4190 - val_acc: 0.6909\n",
      "Epoch 4/100\n",
      "1595/1595 [==============================] - 398s 249ms/step - loss: 0.4711 - acc: 0.8872 - val_loss: 1.5084 - val_acc: 0.6955\n",
      "Epoch 5/100\n",
      "1595/1595 [==============================] - 395s 248ms/step - loss: 0.4307 - acc: 0.9019 - val_loss: 1.2764 - val_acc: 0.7318\n"
     ]
    }
   ],
   "source": [
    "# VGG16 trzecia architektura\n",
    "optimizer = Adam()\n",
    "\n",
    "base_model = VGG16(weights='imagenet', include_top=False, input_shape=image_shape)\n",
    "\n",
    "for layer in base_model.layers[1:]: \n",
    "    layer.trainable = False \n",
    "model, VGG16_224_arch3 = A.arch_TL_3(image_shape, num_classes, callbacks, train_generator, nb_train_samples*multiplier,\\\n",
    "                       validation_generator,nb_validation_samples,batch_size,test_generator,nb_test_samples,\\\n",
    "                      regularizer,optimizer, base_model)\n",
    "filename = '/home/ralph/ml/Sages/Zaliczenie/final/results/eval_VGG16_224_arch3'\n",
    "outfile = open(filename,'wb')\n",
    "pickle.dump(VGG16_224_arch3,outfile)\n",
    "outfile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Odblokowuje ostatani blok konwolucji\n",
    "for layer in model.layers[0].layers[17:]: \n",
    "    layer.trainable = True\n",
    "  \n",
    "optimizer = Adam(0.00001, decay=0.00000001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "vgg16 (Model)                (None, 7, 7, 512)         14714688  \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 25088)             0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 512)               12845568  \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 128)               65664     \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 27,627,210\n",
      "Trainable params: 19,991,946\n",
      "Non-trainable params: 7,635,264\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "1595/1595 [==============================] - 401s 251ms/step - loss: 0.3613 - acc: 0.9177 - val_loss: 1.1126 - val_acc: 0.7591\n",
      "Epoch 2/100\n",
      "1595/1595 [==============================] - 398s 249ms/step - loss: 0.2583 - acc: 0.9518 - val_loss: 1.2864 - val_acc: 0.7500\n",
      "Epoch 3/100\n",
      "1595/1595 [==============================] - 399s 250ms/step - loss: 0.2434 - acc: 0.9590 - val_loss: 1.0447 - val_acc: 0.8091\n",
      "Epoch 4/100\n",
      "1595/1595 [==============================] - 399s 250ms/step - loss: 0.2066 - acc: 0.9715 - val_loss: 0.8962 - val_acc: 0.8409\n",
      "Epoch 5/100\n",
      "1595/1595 [==============================] - 400s 250ms/step - loss: 0.1876 - acc: 0.9782 - val_loss: 1.0282 - val_acc: 0.8273\n",
      "Epoch 6/100\n",
      "1595/1595 [==============================] - 398s 250ms/step - loss: 0.1723 - acc: 0.9826 - val_loss: 0.9493 - val_acc: 0.8273\n",
      "Epoch 7/100\n",
      "1595/1595 [==============================] - 399s 250ms/step - loss: 0.1662 - acc: 0.9843 - val_loss: 0.9149 - val_acc: 0.8500\n"
     ]
    }
   ],
   "source": [
    "# VGG16 - druga faza\n",
    "# Odblokowuje ostatani blok konwolucji\n",
    "for layer in model.layers[0].layers[15:]: \n",
    "    layer.trainable = True\n",
    "   \n",
    "optimizer = Adam(0.00001, decay=0.00000001)\n",
    "\n",
    "model, VGG16_224_arch3_2 = A.TL_phase2(image_shape, num_classes, callbacks, train_generator, nb_train_samples*multiplier,\\\n",
    "                       validation_generator,nb_validation_samples,batch_size,test_generator,nb_test_samples,\\\n",
    "                      regularizer,optimizer, model)\n",
    "filename = '/home/ralph/ml/Sages/Zaliczenie/final/results/eval_VGG16_224_arch3_2'\n",
    "outfile = open(filename,'wb')\n",
    "pickle.dump(VGG16_224_arch3_2,outfile)\n",
    "outfile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Architektura: eval_arch_6 miałą acc na zbiorze testowym równe: 0.08\n",
      "Architektura: eval_arch_8 miałą acc na zbiorze testowym równe: 0.09\n",
      "Architektura: eval_arch_7 miałą acc na zbiorze testowym równe: 0.09\n",
      "Architektura: eval_arch_9 miałą acc na zbiorze testowym równe: 0.10\n",
      "Architektura: eval_arch_4 miałą acc na zbiorze testowym równe: 0.10\n",
      "Architektura: eval_arch_3 miałą acc na zbiorze testowym równe: 0.10\n",
      "Architektura: eval_arch_10 miałą acc na zbiorze testowym równe: 0.11\n",
      "Architektura: eval_arch_5 miałą acc na zbiorze testowym równe: 0.11\n",
      "Architektura: eval_arch_1 miałą acc na zbiorze testowym równe: 0.30\n",
      "Architektura: eval_arch_2 miałą acc na zbiorze testowym równe: 0.39\n",
      "Architektura: eval_VGG16_arch1 miałą acc na zbiorze testowym równe: 0.41\n",
      "Architektura: eval_VGG16_arch2 miałą acc na zbiorze testowym równe: 0.42\n",
      "Architektura: eval_Xception_arch3 miałą acc na zbiorze testowym równe: 0.43\n",
      "Architektura: eval_VGG19_arch1 miałą acc na zbiorze testowym równe: 0.43\n",
      "Architektura: eval_VGG19_arch2 miałą acc na zbiorze testowym równe: 0.45\n",
      "Architektura: eval_VGG19_arch3 miałą acc na zbiorze testowym równe: 0.46\n",
      "Architektura: eval_VGG19_arch1_2 miałą acc na zbiorze testowym równe: 0.46\n",
      "Architektura: eval_VGG19_arch3_2 miałą acc na zbiorze testowym równe: 0.47\n",
      "Architektura: eval_Xception_arch1 miałą acc na zbiorze testowym równe: 0.47\n",
      "Architektura: eval_Xception_all_arch2 miałą acc na zbiorze testowym równe: 0.48\n",
      "Architektura: eval_VGG16_arch2_2 miałą acc na zbiorze testowym równe: 0.49\n",
      "Architektura: eval_VGG16_arch3 miałą acc na zbiorze testowym równe: 0.50\n",
      "Architektura: eval_VGG16_arch3_2 miałą acc na zbiorze testowym równe: 0.50\n",
      "Architektura: eval_VGG19_arch2_2 miałą acc na zbiorze testowym równe: 0.50\n",
      "Architektura: eval_Xception_arch2 miałą acc na zbiorze testowym równe: 0.52\n",
      "Architektura: eval_VGG16_arch1_2 miałą acc na zbiorze testowym równe: 0.52\n",
      "Architektura: eval_Xception_arch3_2 miałą acc na zbiorze testowym równe: 0.52\n",
      "Architektura: eval_Xception_arch2_2 miałą acc na zbiorze testowym równe: 0.54\n",
      "Architektura: eval_VGG16_224_arch3 miałą acc na zbiorze testowym równe: 0.68\n",
      "Architektura: eval_VGG16_224_arch3_2 miałą acc na zbiorze testowym równe: 0.80\n"
     ]
    }
   ],
   "source": [
    "scores=[]\n",
    "\n",
    "for folder in os.walk('/home/ralph/ml/Sages/Zaliczenie/final/results'):\n",
    "    for file in folder[2]:\n",
    "        filename = '/home/ralph/ml/Sages/Zaliczenie/final/results/' + file\n",
    "        infile = open(filename,'rb')\n",
    "        a=pickle.load(infile)\n",
    "        a.append(file)\n",
    "        scores.append(a)\n",
    "        infile.close()\n",
    "              \n",
    "# print(scores)\n",
    "            \n",
    "def getKey(item):\n",
    "    return item[2]\n",
    "scores = sorted(scores, key=getKey)    \n",
    "        \n",
    "for score in scores:\n",
    "    print(\"Architektura: {} miałą acc na zbiorze testowym równe: {:.2f}\".format(score[-1],score[2]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Koniec\n",
    "\n",
    "Zatrzymam się w tym miejscu, mógłbym trenować bardziej złożone modele jak choćby wcześniej trenowany Xception ale mój sprzęt komputerowy nie pozwla na trenowanie obrazków w rozdzielczoscie 299x299 na tak duzych sieciach.\n",
    "\n",
    "Zapiszę więc model za pomocą pickle i przygotuję prostą stronę we Flasku do oceny obrazków."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = '/home/ralph/ml/Sages/Zaliczenie/final/VGG16_224x224x3_D512_D128.model'\n",
    "outfile = open(filename,'wb')\n",
    "pickle.dump(model,outfile)\n",
    "outfile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
